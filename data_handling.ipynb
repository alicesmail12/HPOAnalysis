{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from statsmodels.stats.proportion import proportions_ztest\n",
    "from pyhpo import Ontology\n",
    "_ = Ontology()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_parents(hpo_id):\n",
    "    \"\"\"\n",
    "    Recursively get all parent terms of a HPO term\n",
    "    \"\"\"\n",
    "    term = Ontology.get_hpo_object(hpo_id)\n",
    "    parents = set()\n",
    "    for parent in term.parents:\n",
    "        parent_id = str(parent)[:10]\n",
    "        parents.add(parent_id)\n",
    "        parents |= get_all_parents(parent_id)\n",
    "    return parents\n",
    "\n",
    "def get_all_children(hpo_id):\n",
    "    \"\"\"\n",
    "    Recursively get all child terms of a HPO term\n",
    "    \"\"\"\n",
    "    term = Ontology.get_hpo_object(hpo_id)\n",
    "    children = set()\n",
    "    for child in term.children:\n",
    "        child_id = str(child)[13:]\n",
    "        children.add(child_id)\n",
    "        children |= get_all_children(child_id)\n",
    "    return children\n",
    "\n",
    "def get_hpo_term(hpo_id):\n",
    "    \"\"\"\n",
    "    Get the name of an HPO term\n",
    "    \"\"\"\n",
    "    term = Ontology.get_hpo_object(hpo_id)\n",
    "    return str(term)[13:] if term else None\n",
    "\n",
    "\n",
    "def get_hpo_id(hpo_id):\n",
    "    \"\"\"\n",
    "    Get the name of an HPO term\n",
    "    \"\"\"\n",
    "    term = Ontology.get_hpo_object(hpo_id)\n",
    "    return str(term)[:10] if term else None\n",
    "\n",
    "\n",
    "def get_frequency(hpo_terms):\n",
    "    \"\"\"\n",
    "    Get frequency of HPO terms\n",
    "    \"\"\"\n",
    "    return len(str(hpo_terms).split('|'))\n",
    "\n",
    "\n",
    "def filter_phenotype_name_list(input_list, parent_terms):\n",
    "    \"\"\"\n",
    "    Filter a list using the parent_terms list\n",
    "    \"\"\"\n",
    "    return [term for term in input_list if term in parent_terms]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Propagating HPO terms in DECIPHER dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import DECIPHER dataset csv\n",
    "decipher_data = pd.read_csv('decipher.csv', header=0)\n",
    "\n",
    "# Filter for pathogenicity\n",
    "decipher_data = decipher_data[(decipher_data[\"pathogenicity\"] == \"Pathogenic\") | (decipher_data[\"pathogenicity\"] == \"Likely pathogenic\")]\n",
    "\n",
    "# Create column showing HPO terms per patient\n",
    "decipher_data['HPO_terms_freq'] = decipher_data['phenotype_names'].apply(get_frequency)\n",
    "\n",
    "# Remove patients with 0 HPO terms\n",
    "decipher_data = decipher_data[decipher_data['phenotype_names'].notna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Propagate HPO term IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of strings containing HPO terms for each patient\n",
    "phenotype_names = decipher_data[\"hpo_accessions\"].tolist()\n",
    "\n",
    "# Go through list of strings, to create list of lists\n",
    "phenotype_name_list = []\n",
    "for list_phenotypes in phenotype_names:\n",
    "    list_phenotypes = str(list_phenotypes)\n",
    "    list_phenotypes = list_phenotypes.split('|')\n",
    "    phenotype_name_list.append(list_phenotypes)\n",
    "\n",
    "# Call function for list in phenotype_name_list (list of lists) and add parent IDs to list\n",
    "for phenotype_list in phenotype_name_list:\n",
    "    new_phenotypes = set()\n",
    "    for phenotype in phenotype_list:\n",
    "        parents = get_all_parents(phenotype)\n",
    "        new_phenotypes |= parents \n",
    "        for phenotype in list(new_phenotypes):\n",
    "            if str(phenotype) not in phenotype_list:\n",
    "                phenotype_list.append(phenotype)\n",
    "\n",
    "# Add column with all parent HPO IDs\n",
    "decipher_data[\"propagated_terms\"] = phenotype_name_list\n",
    "decipher_data[\"propagated_terms\"] = decipher_data[\"propagated_terms\"].apply('|'.join)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get propagated term names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split HPO IDs column by '|'\n",
    "hpo_ids = decipher_data['propagated_terms'].str.split('|')\n",
    "\n",
    "# Iterate through each list of HPO IDs and apply HPO term function\n",
    "hpo_terms = []\n",
    "for ids in hpo_ids:\n",
    "    terms = [get_hpo_term(hpo_id) for hpo_id in ids]\n",
    "    hpo_terms.append('|'.join(terms))\n",
    "\n",
    "# Add new column to dataframe with HPO terms\n",
    "decipher_data['propagated_names'] = hpo_terms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Identifying top-level parent HPO terms**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a list of parent terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get child terms of \"Phenotypic abnormality\"\n",
    "parent_terms = []\n",
    "term = Ontology.get_hpo_object(\"Phenotypic abnormality\")\n",
    "for hpo in term.children:\n",
    "    hpo = str(hpo)\n",
    "    hpo_id = (hpo[0:10])\n",
    "    parent_terms.append(hpo_id)\n",
    "\n",
    "# Replace \"Abnormality of the musculoskeletal system\" with abnormalities of the skeletal system, musculature and connective tissue\n",
    "parent_terms.extend([\"HP:0000924\", \"HP:0003549\", \"HP:0003011\"])\n",
    "parent_terms.remove(\"HP:0033127\")\n",
    "\n",
    "# Convert HPO IDs to HPO names\n",
    "parent_names = []\n",
    "for hpo in parent_terms:\n",
    "    hpo_name = get_hpo_term(hpo)\n",
    "    parent_names.append(hpo_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter propagated_terms using parent terms list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of hpo terms for each patient\n",
    "phenotype_names = decipher_data[\"propagated_terms\"].tolist()\n",
    "\n",
    "# Go through list of strings, to create list of lists\n",
    "phenotype_name_list = []\n",
    "for list_phenotypes in phenotype_names:\n",
    "    list_phenotypes = list_phenotypes.split('|')\n",
    "    phenotype_name_list.append(list_phenotypes)\n",
    "\n",
    "# Filter list of lists\n",
    "filtered_lists = []\n",
    "for list_phenotypes in phenotype_name_list:\n",
    "    list_phenotypes = filter_phenotype_name_list(list_phenotypes, parent_terms)\n",
    "    filtered_lists.append(list_phenotypes)\n",
    "\n",
    "# Add filtered list as new column to decipher_data\n",
    "decipher_data[\"parent_terms\"] = filtered_lists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Filtering DECIPHER dataset for gene list**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import gene list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read csv and generate list of genes\n",
    "gene_list = pd.read_csv('gene_list.csv', header=0)\n",
    "gene_names = gene_list[\"gene\"].to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter using gene list\n",
    "decipher_data_filtered = decipher_data[decipher_data[\"gene\"].isin(gene_names)]\n",
    "\n",
    "# Check which patients have more than 1 variant\n",
    "duplicates = decipher_data_filtered[decipher_data_filtered.duplicated(subset='# patient_id')]\n",
    "\n",
    "if len(duplicates) > 0:\n",
    "    non_unique_patients = list(duplicates['# patient_id'])#.unique())\n",
    "    #print(f\"Patients with non-unique variants: {non_unique_patients}\\n\")\n",
    "    patient_genes = {}\n",
    "    for patient_id in non_unique_patients:\n",
    "        patient_data = decipher_data_filtered[decipher_data_filtered['# patient_id'] == patient_id]\n",
    "        genes = list(patient_data['gene'].unique())\n",
    "        patient_genes[patient_id] = genes\n",
    "    for patient_id, genes in patient_genes.items():\n",
    "        #print(f\"Patient {patient_id} has variants in genes: {genes}\")\n",
    "\n",
    "# Remove duplicate patients\n",
    "decipher_data_filtered = decipher_data_filtered.drop_duplicates(subset=['# patient_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group by PcG/TrxG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain lists of genes with PcG, TrxG, PcG/TrxG membership\n",
    "PcG_genes = gene_list.loc[gene_list['group_membership'] == \"PcG\"]\n",
    "TrxG_genes = gene_list.loc[gene_list['group_membership'] == \"TrxG\"]\n",
    "PcG_TrxG_genes = gene_list.loc[gene_list['group_membership'] == \"PcG/TrxG\"]\n",
    "\n",
    "# Add column showing gene membership for each patient\n",
    "decipher_data_filtered[\"group\"] = np.where(decipher_data_filtered['gene'].isin(PcG_TrxG_genes[\"gene\"]), \"PcG/TrxG\",\n",
    "                                  np.where(decipher_data_filtered['gene'].isin(PcG_genes[\"gene\"]), \"PcG\", \"TrxG\"))\n",
    "\n",
    "decipher_data_filtered.to_csv(\"filtered.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total number of unique HPO terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find frequency of all HPO terms in DECIPHER dataset\n",
    "decipher_data_combined = pd.concat([decipher_data_rev, decipher_data_filtered], axis=0)\n",
    "\n",
    "# Unique HPO terms\n",
    "all_terms_in_decipher = set()\n",
    "decipher_data_combined['propagated_names'].str.split(\"|\").apply(all_terms_in_decipher.update)\n",
    "all_terms_in_decipher = list(all_terms_in_decipher)\n",
    "freq_terms_in_decipher = len(all_terms_in_decipher)\n",
    "#print(f\"Number of unique terms across DECIPHER: {freq_terms_in_decipher}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find frequency and percentage of all HPO terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of HPO terms for each patient\n",
    "gene_list_terms = decipher_data_filtered[\"propagated_names\"].tolist()\n",
    "\n",
    "# Find total number of patients\n",
    "gene_list_total_freq = len(decipher_data_filtered)\n",
    "\n",
    "# Go through list of strings, to create list of lists\n",
    "gene_list_terms_list = []\n",
    "for list_phenotypes in gene_list_terms:\n",
    "    list_phenotypes = list_phenotypes.split('|')\n",
    "    gene_list_terms_list.append(list_phenotypes)\n",
    "\n",
    "# Flatten the list of lists into a single list\n",
    "gene_list_flat_list_all = [item for sublist in gene_list_terms_list for item in sublist]\n",
    "\n",
    "# Count the frequency of each term \n",
    "gene_list_freq_count_all = Counter(gene_list_flat_list_all)\n",
    "\n",
    "# Create dictionary, go through parent_terms and add frequency values for each term in freq_count list\n",
    "gene_list_term_freq_all = {}\n",
    "for term in all_terms_in_decipher:\n",
    "    if term in gene_list_freq_count_all:\n",
    "        gene_list_term_freq_all[term] = gene_list_freq_count_all[term]\n",
    "    else:\n",
    "        gene_list_term_freq_all[term] = 0\n",
    "\n",
    "# Calculate percentages, add term:percentage to dictionary term_percent and print the percentage of each term\n",
    "gene_list_term_percent_all = {}\n",
    "for term, freq in gene_list_term_freq_all.items():\n",
    "    term = str(Ontology.get_hpo_object(term))\n",
    "    percent = (freq/gene_list_total_freq)*100\n",
    "    gene_list_term_percent_all[term[13:]] = round(percent, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Reverse filtering DECIPHER dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter for genes not in gene list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for genes that are not in gene list\n",
    "decipher_data_rev = decipher_data[~decipher_data[\"gene\"].isin(gene_names)]\n",
    "\n",
    "# Remove duplicate patients\n",
    "decipher_data_rev = decipher_data_rev.drop_duplicates(subset=['# patient_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find frequency and percentage of all HPO terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of HPO terms for each patient\n",
    "rev_terms = decipher_data_rev[\"propagated_names\"].tolist()\n",
    "\n",
    "# Find total number of patients\n",
    "rev_total_freq = len(decipher_data_rev)\n",
    "\n",
    "# Go through list of strings, to create list of lists\n",
    "rev_terms_list = []\n",
    "for list_phenotypes in rev_terms:\n",
    "    list_phenotypes = list_phenotypes.split('|')\n",
    "    rev_terms_list.append(list_phenotypes)\n",
    "\n",
    "# Flatten the list of lists into a single list\n",
    "rev_flat_list_all = [item for sublist in rev_terms_list for item in sublist]\n",
    "\n",
    "# Count the frequency of each term \n",
    "rev_freq_count_all = Counter(rev_flat_list_all)\n",
    "\n",
    "# Create dictionary, go through parent_terms and add frequency values for each term in freq_count list\n",
    "rev_term_freq_all = {}\n",
    "for term in all_terms_in_decipher:\n",
    "    if term in rev_freq_count_all:\n",
    "        rev_term_freq_all[term] = rev_freq_count_all[term]\n",
    "    else:\n",
    "        rev_term_freq_all[term] = 0\n",
    "\n",
    "# Calculate percentages, add term:percentage to dictionary term_percent and print the percentage of each term\n",
    "rev_term_percent_all = {}\n",
    "for term, freq in rev_term_freq_all.items():\n",
    "    term = str(Ontology.get_hpo_object(term))\n",
    "    percent = (freq/rev_total_freq)*100\n",
    "    rev_term_percent_all[term[13:]] = round(percent, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **HPO frequencies: comparing top-level and unpropagated terms (gene list vs rest of DECIPHER)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare frequency of top-level HPO terms per patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count top-level HPO terms for each gene list patient\n",
    "gene_list_top_level = decipher_data_filtered[[\"# patient_id\", \"parent_terms\"]]\n",
    "gene_list_top_level[\"parent_terms\"] = gene_list_top_level[\"parent_terms\"].apply('|'.join)\n",
    "gene_list_top_level['HPO_parent_terms_freq'] = gene_list_top_level['parent_terms'].apply(get_frequency)\n",
    "\n",
    "# Count top-level HPO terms for each patient in the rest of DECIPHER\n",
    "rev_top_level = decipher_data_rev[[\"# patient_id\", \"parent_terms\"]]\n",
    "rev_top_level[\"parent_terms\"] = rev_top_level[\"parent_terms\"].apply('|'.join)\n",
    "rev_top_level['HPO_parent_terms_freq'] = rev_top_level['parent_terms'].apply(get_frequency)\n",
    "\n",
    "# Find number of patients with each HPO term frequency \n",
    "gene_list_counts_top_level = Counter(gene_list_top_level['HPO_parent_terms_freq'])\n",
    "rev_list_counts_top_level = Counter(rev_top_level['HPO_parent_terms_freq'])\n",
    "\n",
    "# Convert counter object into dictionary\n",
    "gene_list_counts_top_level = dict(gene_list_counts_top_level)\n",
    "rev_list_counts_top_level = dict(rev_list_counts_top_level)\n",
    "\n",
    "# Calculate percent of patients in each group with each frequency\n",
    "gene_list_percent_top_level = {key: (value / gene_list_total_freq)*100 for key, value in gene_list_counts_top_level.items()}\n",
    "rev_percent_top_level = {key: (value / rev_total_freq)*100 for key, value in rev_list_counts_top_level.items()}\n",
    "\n",
    "# Create dataframe comparing gene list patients with patients in the rest of DECIPHER\n",
    "top_level_hpo_percent = pd.DataFrame({\"gene_list_percent\": pd.Series(gene_list_percent_top_level), \"rev_percent\": pd.Series(rev_percent_top_level)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare frequency of unpropagated HPO terms per patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find number of patients with each HPO term frequency \n",
    "gene_list_counts_unpropagated = Counter(decipher_data_filtered['HPO_terms_freq'])\n",
    "rev_list_counts_unpropagated = Counter(decipher_data_rev['HPO_terms_freq'])\n",
    "\n",
    "# Convert counter object into dictionary\n",
    "gene_list_counts_unpropagated = dict(gene_list_counts_unpropagated)\n",
    "rev_list_counts_unpropagated = dict(rev_list_counts_unpropagated)\n",
    "\n",
    "# Calculate percent of patients in each group with each frequency\n",
    "gene_list_percent_unpropagated = {key: (value / gene_list_total_freq)*100 for key, value in gene_list_counts_unpropagated.items()}\n",
    "rev_percent_unpropagated = {key: (value / rev_total_freq)*100 for key, value in rev_list_counts_unpropagated.items()}\n",
    "\n",
    "# Create dataframe comparing gene list patients with patients in the rest of DECIPHER\n",
    "unpropagated_hpo_percent = pd.DataFrame({\"gene_list_percent\": pd.Series(gene_list_percent_unpropagated), \"rev_percent\": pd.Series(rev_percent_unpropagated)})\n",
    "unpropagated_hpo_percent = unpropagated_hpo_percent.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create unpropated HPO term frequency bins (for histogram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histogram = pd.DataFrame(columns = [\"bin\", \"gene_list_percent\", \"rev_percent\"])\n",
    "histogram[\"bin\"] = (\"1-4\", \"5-9\", \"10-14\", \"15-19\", \"20-24\", \"25-29\", \"30-34\", \"35-39\")\n",
    "histogram[\"gene_list_percent\"] = (sum(unpropagated_hpo_percent[\"gene_list_percent\"][0:4]), sum(unpropagated_hpo_percent[\"gene_list_percent\"][4:9]), sum(unpropagated_hpo_percent[\"gene_list_percent\"][9:14]), sum(unpropagated_hpo_percent[\"gene_list_percent\"][14:19]), sum(unpropagated_hpo_percent[\"gene_list_percent\"][19:24]), sum(unpropagated_hpo_percent[\"gene_list_percent\"][24:29]), sum(unpropagated_hpo_percent[\"gene_list_percent\"][29:34]), sum(unpropagated_hpo_percent[\"gene_list_percent\"][34:39]))\n",
    "histogram[\"rev_percent\"] = (sum(unpropagated_hpo_percent[\"rev_percent\"][0:4]), sum(unpropagated_hpo_percent[\"rev_percent\"][4:9]), sum(unpropagated_hpo_percent[\"rev_percent\"][9:14]), sum(unpropagated_hpo_percent[\"rev_percent\"][14:19]), sum(unpropagated_hpo_percent[\"rev_percent\"][19:24]), sum(unpropagated_hpo_percent[\"rev_percent\"][24:29]), sum(unpropagated_hpo_percent[\"rev_percent\"][29:34]), sum(unpropagated_hpo_percent[\"rev_percent\"][34:39]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **HPO terms: testing for significance (gene list vs rest of DECIPHER)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine filtered and reverse filtered dictionaries into dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_list_rev_hpo = pd.DataFrame({'hpo_term': list(gene_list_term_percent_all.keys()), 'gene_list_percent': list(gene_list_term_percent_all.values()), 'gene_list_freq': list(gene_list_term_freq_all.values()), \n",
    "'rev_percent': list(rev_term_percent_all.values()), 'rev_freq': list(rev_term_freq_all.values())})\n",
    "gene_list_rev_hpo[\"total_freq\"] = gene_list_rev_hpo[\"gene_list_freq\"] + gene_list_rev_hpo[\"rev_freq\"] \n",
    "gene_list_rev_hpo = gene_list_rev_hpo.sort_values('hpo_term')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate p-values using 2-proportions Z-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through each HPO term and calculate p-value\n",
    "for index, row in gene_list_rev_hpo.iterrows():\n",
    "    hpo_term = row[\"hpo_term\"]\n",
    "    gene_list_freq = row[\"gene_list_freq\"]\n",
    "    rev_freq = row[\"rev_freq\"]\n",
    "    frequencies = np.array([gene_list_freq, rev_freq])\n",
    "    totals = np.array([gene_list_total_freq, rev_total_freq])\n",
    "    stat, p_value = proportions_ztest(count=frequencies, nobs=totals, alternative=\"two-sided\")\n",
    "    gene_list_rev_hpo.loc[index, \"p_value\"] = p_value\n",
    "\n",
    "# Adjust p-value (Bonferroni) and identify significantly different terms\n",
    "gene_list_rev_hpo[\"adj_p_value\"] = gene_list_rev_hpo[\"p_value\"] * freq_terms_in_decipher\n",
    "gene_list_rev_hpo['significant'] = np.where(gene_list_rev_hpo['adj_p_value']<0.05, \"Y\", \"N\")\n",
    "\n",
    "# Get significant HPO terms by total number of HPO terms\n",
    "gene_list_rev_hpo_significant = gene_list_rev_hpo[(gene_list_rev_hpo['significant']==\"Y\") & (gene_list_rev_hpo['total_freq']>50)]\n",
    "gene_list_rev_hpo_significant['change'] = np.where(gene_list_rev_hpo_significant['gene_list_percent']>gene_list_rev_hpo_significant['rev_percent'], \"Increase\", \"Decrease\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get top-level HPO terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_list_rev_hpo_top_level = gene_list_rev_hpo[gene_list_rev_hpo['hpo_term'].isin(parent_names)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **HPO terms: testing for significance (PcG vs TrxG)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split filtered DECIPHER dataset into PcG and TrxG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PcG_decipher_data_filtered = decipher_data_filtered[decipher_data_filtered[\"group\"] == \"PcG\"]\n",
    "TrxG_decipher_data_filtered = decipher_data_filtered[decipher_data_filtered[\"group\"] == \"TrxG\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unique HPO terms across PcG and TrxG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find frequency of all HPO terms in DECIPHER dataset\n",
    "PcG_TrxG_combined = pd.concat([PcG_decipher_data_filtered, TrxG_decipher_data_filtered], axis=0)\n",
    "\n",
    "# Unique HPO terms\n",
    "all_terms_in_PcG_TrxG = set()\n",
    "PcG_TrxG_combined['propagated_terms'].str.split(\"|\").apply(all_terms_in_PcG_TrxG.update)\n",
    "all_terms_in_PcG_TrxG = list(all_terms_in_PcG_TrxG)\n",
    "freq_terms_in_PcG_TrxG = len(all_terms_in_PcG_TrxG)\n",
    "#print(f\"Number of unique terms across PcG and TrxG: {freq_terms_in_PcG_TrxG}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find frequency and percentage of terms in PcG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of hpo terms for each patient\n",
    "PcG_phenotype_names = PcG_decipher_data_filtered[\"propagated_terms\"].tolist()\n",
    "\n",
    "# Go through list of strings, to create list of lists\n",
    "PcG_phenotype_name_list = []\n",
    "for list_phenotypes in PcG_phenotype_names:\n",
    "    list_phenotypes = list_phenotypes.split('|')\n",
    "    PcG_phenotype_name_list.append(list_phenotypes)\n",
    "\n",
    "# Find number of PcG patients\n",
    "PcG_total_freq = len(PcG_decipher_data_filtered)\n",
    "\n",
    "# Flatten the list of lists into a single list\n",
    "PcG_flat_list = [item for sublist in PcG_phenotype_name_list for item in sublist]\n",
    "\n",
    "# Count the frequency of each term using a Counter object\n",
    "PcG_freq_count = Counter(PcG_flat_list)\n",
    "\n",
    "# Create dictionary and add frequency values for each term in freq_count list\n",
    "PcG_term_id_freq = {}\n",
    "for term in all_terms_in_PcG_TrxG:\n",
    "    if term in PcG_freq_count:\n",
    "        PcG_term_id_freq[term] = PcG_freq_count[term]\n",
    "    else:\n",
    "        PcG_term_id_freq[term] = 0\n",
    "\n",
    "# Convert HPO IDs into HPO names\n",
    "PcG_term_freq = {}\n",
    "for term, freq in PcG_term_id_freq.items():\n",
    "    term = str(Ontology.get_hpo_object(term))\n",
    "    PcG_term_freq[term[13:]] = freq\n",
    "    PcG_term_freq[\"total\"] = PcG_total_freq\n",
    "\n",
    "# Calculate percentages, add term:percentage to dictionary term_percent and print the percentage of each term\n",
    "PcG_term_percent = {}\n",
    "for term, freq in PcG_term_freq.items():\n",
    "    percent = (freq/PcG_total_freq)*100\n",
    "    PcG_term_percent[term] = round(percent, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find frequency and percentage of terms in TrxG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of hpo terms for each patient\n",
    "TrxG_phenotype_names = TrxG_decipher_data_filtered[\"propagated_terms\"].tolist()\n",
    "\n",
    "# Go through list of strings, to create list of lists\n",
    "TrxG_phenotype_name_list = []\n",
    "for list_phenotypes in TrxG_phenotype_names:\n",
    "    list_phenotypes = list_phenotypes.split('|')\n",
    "    TrxG_phenotype_name_list.append(list_phenotypes)\n",
    "\n",
    "# Find number of TrxG patients\n",
    "TrxG_total_freq = len(TrxG_decipher_data_filtered)\n",
    "\n",
    "# Flatten the list of lists into a single list\n",
    "TrxG_flat_list = [item for sublist in TrxG_phenotype_name_list for item in sublist]\n",
    "\n",
    "# Count the frequency of each term using a Counter object\n",
    "TrxG_freq_count = Counter(TrxG_flat_list)\n",
    "\n",
    "# Create dictionary, go through parent_terms and add frequency values for each term in freq_count list\n",
    "TrxG_term_id_freq = {}\n",
    "for term in all_terms_in_PcG_TrxG:\n",
    "    if term in TrxG_freq_count:\n",
    "        TrxG_term_id_freq[term] = TrxG_freq_count[term]\n",
    "    else:\n",
    "        TrxG_term_id_freq[term] = 0\n",
    "\n",
    "# Convert HPO IDs into HPO names\n",
    "TrxG_term_freq = {}\n",
    "for term, freq in TrxG_term_id_freq.items():\n",
    "    term = str(Ontology.get_hpo_object(term))\n",
    "    TrxG_term_freq[term[13:]] = freq\n",
    "    TrxG_term_freq[\"total\"] = TrxG_total_freq\n",
    "\n",
    "# Calculate percentages, add term:percentage to dictionary term_percent and print the percentage of each term\n",
    "TrxG_term_percent = {}\n",
    "for term, freq in TrxG_term_freq.items():\n",
    "    percent = (freq/TrxG_total_freq)*100\n",
    "    TrxG_term_percent[term] = round(percent, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine PcG and TrxG dictionaries into dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PcG_TrxG_hpo = pd.DataFrame({'hpo_term': list(PcG_term_freq.keys()), 'PcG_percent': list(PcG_term_percent.values()), 'PcG_freq': list(PcG_term_freq.values()), \n",
    "'TrxG_percent': list(TrxG_term_percent.values()), 'TrxG_freq': list(TrxG_term_freq.values())})\n",
    "PcG_TrxG_hpo = PcG_TrxG_hpo.sort_values('hpo_term')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate p-values using 2-proportions Z-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through each HPO term and calculate p-value\n",
    "for index, row in PcG_TrxG_hpo.iterrows():\n",
    "    hpo_term = row[\"hpo_term\"]\n",
    "    PcG_freq = row[\"PcG_freq\"]\n",
    "    TrxG_freq = row[\"TrxG_freq\"]\n",
    "    frequencies = np.array([PcG_freq, TrxG_freq])\n",
    "    totals = np.array([PcG_total_freq, TrxG_total_freq])\n",
    "    stat, p_value = proportions_ztest(count=frequencies, nobs=totals, alternative=\"two-sided\")\n",
    "    PcG_TrxG_hpo.loc[index, \"p_value\"] = p_value\n",
    "\n",
    "# Adjust p-value (Bonferroni) and identify significantly different terms\n",
    "PcG_TrxG_hpo[\"adj_p_value\"] = PcG_TrxG_hpo[\"p_value\"] * freq_terms_in_PcG_TrxG\n",
    "PcG_TrxG_hpo['significant'] = np.where(PcG_TrxG_hpo['adj_p_value']<0.05, \"Y\", \"N\")\n",
    "PcG_TrxG_hpo_significant = PcG_TrxG_hpo[(PcG_TrxG_hpo['significant']==\"Y\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **HPO top-level terms: three-way pairwise comparisons (PcG vs rest of DECIPHER & TrxG vs rest of DECIPHER)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge relevant dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rev_hpo_subset = gene_list_rev_hpo[[\"hpo_term\", \"rev_freq\"]]\n",
    "PcG_TrxG_hpo_subset = PcG_TrxG_hpo[[\"hpo_term\", \"PcG_freq\", \"TrxG_freq\"]]\n",
    "\n",
    "PcG_TrxG_rev_combined = pd.merge(rev_hpo_subset, PcG_TrxG_hpo_subset, on=\"hpo_term\")\n",
    "PcG_TrxG_rev_combined_top_level = PcG_TrxG_rev_combined[PcG_TrxG_rev_combined['hpo_term'].isin(parent_names)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare TrxG with rest of DECIPHER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through each HPO term and calculate p-value\n",
    "for index, row in PcG_TrxG_rev_combined_top_level.iterrows():\n",
    "    hpo_term = row[\"hpo_term\"]\n",
    "    TrxG_freq = row[\"TrxG_freq\"]\n",
    "    rev_freq = row[\"rev_freq\"]\n",
    "    frequencies = np.array([TrxG_freq, rev_freq])\n",
    "    totals = np.array([TrxG_total_freq, rev_total_freq])\n",
    "    stat, p_value = proportions_ztest(count=frequencies, nobs=totals, alternative=\"two-sided\")\n",
    "    PcG_TrxG_rev_combined_top_level.loc[index, \"TrxG_vs_rev_p_value\"] = p_value\n",
    "\n",
    "# Adjust p-value (Bonferroni) and identify significantly different terms\n",
    "PcG_TrxG_rev_combined_top_level[\"TrxG_vs_rev_adj_p_value\"] = PcG_TrxG_rev_combined_top_level[\"TrxG_vs_rev_p_value\"] * freq_terms_in_decipher\n",
    "PcG_TrxG_rev_combined_top_level['TrxG_vs_rev_significant'] = np.where(PcG_TrxG_rev_combined_top_level['TrxG_vs_rev_adj_p_value']<0.05, \"Y\", \"N\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare PcG with rest of DECIPHER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through each HPO term and calculate p-value\n",
    "for index, row in PcG_TrxG_rev_combined_top_level.iterrows():\n",
    "    hpo_term = row[\"hpo_term\"]\n",
    "    PcG_freq = row[\"PcG_freq\"]\n",
    "    rev_freq = row[\"rev_freq\"]\n",
    "    frequencies = np.array([PcG_freq, rev_freq])\n",
    "    totals = np.array([PcG_total_freq, rev_total_freq])\n",
    "    stat, p_value = proportions_ztest(count=frequencies, nobs=totals, alternative=\"two-sided\")\n",
    "    PcG_TrxG_rev_combined_top_level.loc[index, \"PcG_vs_rev_p_value\"] = p_value\n",
    "\n",
    "# Adjust p-value (Bonferroni) and identify significantly different terms\n",
    "PcG_TrxG_rev_combined_top_level[\"PcG_vs_rev_adj_p_value\"] = PcG_TrxG_rev_combined_top_level[\"PcG_vs_rev_p_value\"] * freq_terms_in_decipher\n",
    "PcG_TrxG_rev_combined_top_level['PcG_vs_rev_significant'] = np.where(PcG_TrxG_rev_combined_top_level['PcG_vs_rev_adj_p_value']<0.05, \"Y\", \"N\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Output filtered DECIPHER dataset with propagated terms as csv for clustering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decipher_data_filtered.to_csv(\"decipher_filtered.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --------------------------------------------------------------------------------------------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

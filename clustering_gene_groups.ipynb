{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import pairwise_distances\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.cluster import hierarchy\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from collections import Counter\n",
    "from scipy import stats\n",
    "from rpy2.robjects.packages import importr\n",
    "from rpy2.robjects.vectors import FloatVector\n",
    "import matplotlib as matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Import filtered DECIPHER dataset and create binary matrix**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import csv and subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decipher = pd.read_csv('decipher_filtered.csv', header=0)\n",
    "decipher_subset = decipher[[\"gene\", \"propagated_names\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create binary matrix representing each patient (by gene)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decipher_phenotypes = decipher_subset['propagated_names'].str.get_dummies('|')\n",
    "decipher_binary_matrix = pd.concat([decipher_subset[['gene']], decipher_phenotypes], axis=1)\n",
    "decipher_binary_matrix.set_index('gene', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate proportion of patients in each gene group (n>=3) with each phenotype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proportions = decipher_binary_matrix.groupby(decipher_binary_matrix.index).mean()\n",
    "group_sizes = decipher_binary_matrix.groupby(decipher_binary_matrix.index).size()\n",
    "valid_groups = group_sizes[group_sizes >= 3].index\n",
    "proportions = proportions.loc[valid_groups]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert proportions dataframe into gene group binary matrix with 30% cut-off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proportions = proportions.where(proportions > 0.3, 0).where(proportions <= 0.3, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Jaccard similarity and dendrogram**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Jaccard similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Jaccard similarity between patients\n",
    "jaccard_similarity = pd.DataFrame(1-pairwise_distances(proportions.to_numpy(), metric='jaccard'))\n",
    "\n",
    "# Set row and column index to gene names\n",
    "jaccard_similarity.index = proportions.index\n",
    "jaccard_similarity.columns = proportions.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dendrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Dendrogram\n",
    "plt.figure(figsize=(25, 5))\n",
    "sns.set(font_scale=2, font=\"Galvji\")\n",
    "plt.style.use('ggplot')\n",
    "linkage = hierarchy.linkage(jaccard_similarity, 'ward')\n",
    "hierarchy.set_link_color_palette(['#ec726c', \"#a3d0da\", '#d4c32d', '#69af34', '#42968f', '#455986'])\n",
    "hierarchy.dendrogram(linkage, labels=proportions.index, color_threshold=2, above_threshold_color='grey', leaf_font_size=20)\n",
    "plt.axhline(y=2, c='grey', lw=1, linestyle='dashed')\n",
    "plt.xticks(rotation=90)\n",
    "plt.grid()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Clustering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform clustering with the Jaccard similarity matrix\n",
    "n_clusters = 3\n",
    "clustering = AgglomerativeClustering(n_clusters=n_clusters, linkage='ward').fit(jaccard_similarity)\n",
    "\n",
    "# Get the cluster membership for each gene\n",
    "labels = clustering.labels_ + 1\n",
    "genes = proportions.index\n",
    "gene_clusters = {gene: label for gene, label in zip(genes, labels)}\n",
    "\n",
    "# Add the Cluster column to the proportions DataFrame and move it to position [1]\n",
    "proportions.insert(0, \"cluster\", [gene_clusters[gene] for gene in proportions.index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of genes in each cluster\n",
    "clusters = {}\n",
    "for gene, label in gene_clusters.items():\n",
    "    if label in clusters:\n",
    "        clusters[label].append(gene)\n",
    "    else:\n",
    "        clusters[label] = [gene]\n",
    "\n",
    "for label, genes in clusters.items():\n",
    "    print(f\"Cluster {label}: {genes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *-------------------------- Performed t-test on clusters and determined clusters 2 & 3 have an increased mean intracluster similarity score --------------------------*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Compare clusters to find comparatively enriched HPO terms**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign cluster gene lists to objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_2 = clusters[2] \n",
    "cluster_3 = clusters[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find number of patients represented by each cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decipher_cluster_2 = decipher[decipher[\"gene\"].isin(cluster_2)]\n",
    "decipher_cluster_3 = decipher[decipher[\"gene\"].isin(cluster_3)]\n",
    "\n",
    "cluster_2_total_freq = (len(decipher_cluster_2))\n",
    "cluster_3_total_freq = (len(decipher_cluster_3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find unique HPO terms across both clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find frequency of all HPO terms in DECIPHER dataset\n",
    "clusters_2_3_combined = pd.concat([decipher_cluster_2, decipher_cluster_3], axis=0)\n",
    "\n",
    "# Unique HPO terms\n",
    "all_terms_in_cluster_2_3 = set()\n",
    "clusters_2_3_combined['propagated_names'].str.split(\"|\").apply(all_terms_in_cluster_2_3.update)\n",
    "all_terms_in_cluster_2_3 = list(all_terms_in_cluster_2_3)\n",
    "freq_terms_in_cluster_2_3 = len(all_terms_in_cluster_2_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster 2 HPO frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of hpo term strings for each patient\n",
    "cluster_2_hpo = decipher_cluster_2[\"propagated_names\"].tolist()\n",
    "\n",
    "# Go through list of strings, to create list of lists\n",
    "cluster_2_hpo_lists = []\n",
    "for list_phenotypes in cluster_2_hpo:\n",
    "    list_phenotypes = list_phenotypes.split('|')\n",
    "    cluster_2_hpo_lists.append(list_phenotypes)\n",
    "\n",
    "# Flatten the list of lists into a single list\n",
    "cluster_2_flat_list = [item for sublist in cluster_2_hpo_lists for item in sublist]\n",
    "\n",
    "# Count frequency of each term\n",
    "cluster_2_freq_count = Counter(cluster_2_flat_list)\n",
    "\n",
    "# Add frequency values for each term into dictionary\n",
    "cluster_2_term_freq = {}\n",
    "for term in all_terms_in_cluster_2_3:\n",
    "    if term in cluster_2_freq_count:\n",
    "        cluster_2_term_freq[term] = cluster_2_freq_count[term]\n",
    "    else:\n",
    "        cluster_2_term_freq[term] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster 3 HPO frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of hpo term strings for each patient\n",
    "cluster_3_hpo = decipher_cluster_3[\"propagated_names\"].tolist()\n",
    "\n",
    "# Go through list of strings, to create list of lists\n",
    "cluster_3_hpo_lists = []\n",
    "for list_phenotypes in cluster_3_hpo:\n",
    "    list_phenotypes = list_phenotypes.split('|')\n",
    "    cluster_3_hpo_lists.append(list_phenotypes)\n",
    "\n",
    "# Flatten the list of lists into a single list\n",
    "cluster_3_flat_list = [item for sublist in cluster_3_hpo_lists for item in sublist]\n",
    "\n",
    "# Count frequency of each term\n",
    "cluster_3_freq_count = Counter(cluster_3_flat_list)\n",
    "\n",
    "# Add frequency values for each term into dictionary\n",
    "cluster_3_term_freq = {}\n",
    "for term in all_terms_in_cluster_2_3:\n",
    "    if term in cluster_3_freq_count:\n",
    "        cluster_3_term_freq[term] = cluster_3_freq_count[term]\n",
    "    else:\n",
    "        cluster_3_term_freq[term] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dataframe from cluster 2 and 3 dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_freq = pd.DataFrame({'hpo_term': list(cluster_2_term_freq.keys()), 'cluster_2_freq': list(cluster_2_term_freq.values()), 'cluster_3_freq': list(cluster_3_term_freq.values())})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fisher's exact test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in clusters_freq.iterrows():\n",
    "    hpo_term = row[\"hpo_term\"]\n",
    "    cluster_2_freq = row[\"cluster_2_freq\"]\n",
    "    cluster_3_freq = row[\"cluster_3_freq\"]\n",
    "    contingency_arrays = np.array([[cluster_2_freq, cluster_3_freq], [cluster_2_total_freq-cluster_2_freq, cluster_3_total_freq-cluster_3_freq]])\n",
    "    contingency_table = np.asmatrix(contingency_arrays)\n",
    "    odd_ratio, p_value = stats.fisher_exact(contingency_table)\n",
    "    clusters_freq.loc[index, \"p_value\"] = p_value\n",
    "    clusters_freq.loc[index, \"OR\"] = odd_ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjust p-values using Benjamini-Hochberg method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of p-values\n",
    "p_values = list(clusters_freq[\"p_value\"])\n",
    "\n",
    "# Perform adjustment\n",
    "stats = importr('stats')\n",
    "adj_p_values = list(stats.p_adjust(FloatVector(p_values), method = 'BH'))\n",
    "\n",
    "# Assign adjusted p-values to new column\n",
    "clusters_freq[\"adj_p_value\"] = adj_p_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify comparatively increased HPO terms in each cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for significant HPO terms\n",
    "clusters_freq['significant'] = np.where(clusters_freq['adj_p_value']<0.05, \"Y\", \"N\")\n",
    "clusters_freq_significant = clusters_freq[(clusters_freq['significant']==\"Y\")]\n",
    "\n",
    "# Using OR split into HPO terms increased in each cluster \n",
    "increased_cluster_2 = clusters_freq_significant[(clusters_freq_significant[\"OR\"]>1)]\n",
    "increased_cluster_3 = clusters_freq_significant[(clusters_freq_significant[\"OR\"]<1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate percentages\n",
    "increased_cluster_2[\"cluster_2_percent\"] = (increased_cluster_2[\"cluster_2_freq\"])/cluster_2_total_freq\n",
    "increased_cluster_3[\"cluster_2_percent\"] = (increased_cluster_3[\"cluster_2_freq\"])/cluster_2_total_freq\n",
    "\n",
    "increased_cluster_2[\"cluster_3_percent\"] = (increased_cluster_2[\"cluster_3_freq\"])/cluster_3_total_freq\n",
    "increased_cluster_3[\"cluster_3_percent\"] = (increased_cluster_3[\"cluster_3_freq\"])/cluster_3_total_freq\n",
    "\n",
    "# Combine top HPO terms and subset\n",
    "cluster_2_3 = pd.concat([increased_cluster_2, increased_cluster_3], axis=0)\n",
    "cluster_2_3_subset = cluster_2_3[[\"hpo_term\", \"cluster_2_percent\", \"cluster_3_percent\"]]\n",
    "cluster_2_3_subset = cluster_2_3_subset.rename(columns={\"cluster_2_percent\": \"Cluster 2\", \"cluster_3_percent\": \"Cluster 3\"})\n",
    "cluster_2_3_subset = cluster_2_3_subset.set_index(\"hpo_term\")\n",
    "\n",
    "# Define the order of row labels\n",
    "row_order = [\n",
    "# Increased in cluster 3\n",
    "\"Behavioral abnormality\",\n",
    "\"Abnormality of body height\",\n",
    "\"Autistic behavior\",\n",
    "\"Tall stature\",\n",
    "\"Macrocephaly\",\n",
    "\"Increased head circumference\",\n",
    "\"Proportionate tall stature\",\n",
    "\"Overgrowth\",\n",
    "\n",
    "# Increased in cluster 2\n",
    "\"Abnormality of the integument\",\n",
    "\"Abnormality of skin adnexa morphology\",\n",
    "\"Abnormal hair morphology\",\n",
    "\"Abnormal appendicular skeleton morphology\",\n",
    "\"Abnormality of limb bone\",\n",
    "\"Abnormality of limb bone morphology\",\n",
    "\"Abnormal digit morphology\",\n",
    "\"Abnormal hair quantity\",\n",
    "]\n",
    "\n",
    "cluster_2_3_subset.index = pd.Categorical(cluster_2_3_subset.index, categories=row_order, ordered=True)\n",
    "cluster_2_3_subset = cluster_2_3_subset.sort_index()\n",
    "\n",
    "# Heatmap\n",
    "cmap = matplotlib.colors.LinearSegmentedColormap.from_list('custom blue', \n",
    "                                             [(0,    '#B1C877'),\n",
    "                                              (0.5, '#63A1B0'),\n",
    "                                              (1,    '#4464AD')], N=256)\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set(font_scale=1.2, font=\"Galvji\")\n",
    "heatmap = sns.heatmap(cluster_2_3_subset, cmap=cmap, cbar=True, annot=True, vmin=0.0, vmax=0.51, fmt=\".2%\")\n",
    "cbar = heatmap.collections[0].colorbar\n",
    "cbar.set_label('\\nProportion of Patients with Phenotype')\n",
    "plt.subplots_adjust(left=0.4, right=0.95)\n",
    "plt.xlabel(\"Cluster\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --------------------------------------------------------------------------------------------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
